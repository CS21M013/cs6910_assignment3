{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS6910_vanilla_seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e042dbef55b94dab8527fab84191f026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_463b8e13d4944b28a7928379a6c5ac54",
              "IPY_MODEL_130af60f03f749beb1c9a69525feada1"
            ],
            "layout": "IPY_MODEL_134c9393f04a41c09bf47f69e3c3a34f"
          }
        },
        "463b8e13d4944b28a7928379a6c5ac54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7601668422cd455f92d0cf244e62185d",
            "placeholder": "​",
            "style": "IPY_MODEL_ed0c7f36a1c44647b7cd7980dba00569",
            "value": "0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "130af60f03f749beb1c9a69525feada1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6af22765b04435ab64d9c98f8b3a87e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7613da9a59c4554815ba78b66b1faab",
            "value": 1
          }
        },
        "134c9393f04a41c09bf47f69e3c3a34f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7601668422cd455f92d0cf244e62185d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed0c7f36a1c44647b7cd7980dba00569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6af22765b04435ab64d9c98f8b3a87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7613da9a59c4554815ba78b66b1faab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74ae92db2e3c4ea79f1efab77a01af04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_961e99e0c26b4855b7b16c75dba1b0cd",
              "IPY_MODEL_436411caab80462a859f24af15a10e30"
            ],
            "layout": "IPY_MODEL_7580d9f75a1a454fa49c3350eeb68793"
          }
        },
        "961e99e0c26b4855b7b16c75dba1b0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e1b5e1baaf240e8a97315fd00ac842d",
            "placeholder": "​",
            "style": "IPY_MODEL_2404ca5dae104ecc820a38f172bb612c",
            "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "436411caab80462a859f24af15a10e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dae78f3ff7e44672971afd801e6d2310",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1e8ec728c7c46a798b714536ef8e774",
            "value": 1
          }
        },
        "7580d9f75a1a454fa49c3350eeb68793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e1b5e1baaf240e8a97315fd00ac842d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2404ca5dae104ecc820a38f172bb612c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dae78f3ff7e44672971afd801e6d2310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e8ec728c7c46a798b714536ef8e774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "549a793a73c04ab2bac049ce9121d863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1e7a67e3fda426cb5331e22d426badc",
              "IPY_MODEL_f15c323da001441baf8d991bdb588284"
            ],
            "layout": "IPY_MODEL_26ad566a7b7d4c9485109c413e001450"
          }
        },
        "d1e7a67e3fda426cb5331e22d426badc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a90e76f8f249f5a5257b98602b75a7",
            "placeholder": "​",
            "style": "IPY_MODEL_6c48b45f892b42e78219746e92d9ffeb",
            "value": "0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "f15c323da001441baf8d991bdb588284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a41b6bbbf8346d8b13368192cd50fcf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f62dbab24df4815a363d2dc5218d1ce",
            "value": 1
          }
        },
        "26ad566a7b7d4c9485109c413e001450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a90e76f8f249f5a5257b98602b75a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c48b45f892b42e78219746e92d9ffeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a41b6bbbf8346d8b13368192cd50fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f62dbab24df4815a363d2dc5218d1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "BnfIid93ZAPO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPe9yzEMd82h"
      },
      "source": [
        "'''\n",
        "Imports\n",
        "'''\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the Dakshina Dataset"
      ],
      "metadata": {
        "id": "wVWhSPCQZCxg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcrMP9zeeI-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121e66be-1cfe-402c-84f0-6d87df3e6c49"
      },
      "source": [
        "'''\n",
        "Downloading the data\n",
        "'''\n",
        "!curl https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar --output daksh.tar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1915M  100 1915M    0     0   150M      0  0:00:12  0:00:12 --:--:--  151M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90BFybn0eLGH"
      },
      "source": [
        "'''\n",
        "Capturing the data and saving as the Tar file\n",
        "'''\n",
        "%%capture\n",
        "!tar -xvf  'daksh.tar' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juf8qHq0fvy3"
      },
      "source": [
        "'''\n",
        "Function to read the data\n",
        "Input - Data path to read the data\n",
        "Output - input text, target text, input and target tokenizier, input and target tensor\n",
        "'''\n",
        "def data(path,input_tokenizer=None,output_tokenizer=None,input_length=None,output_length=None):\n",
        "  \n",
        "  input_texts = []  #list of input text\n",
        "  output_texts = [] #list of output/target text\n",
        "  \n",
        "  df = pd.read_csv(path,sep=\"\\t\",names=[\"1\", \"2\",\"3\"]).astype(str)\n",
        "  # sampling the input of the tokenizier in None.\n",
        "  if input_tokenizer is None:\n",
        "      df=df.sample(frac=1)\n",
        "  # Adding all the  input and target texts with start sequence and end sequence added to target. \n",
        "  for index, row in df.iterrows():\n",
        "      input_text=row['2']\n",
        "      output_text= row['1']\n",
        "      if output_text =='</s>' or input_text=='</s>': #adding the start character for input and output text\n",
        "        continue\n",
        "      output_text = \"\\t\" + output_text + \"\\n\" #addintg the ending character for both input an the output\n",
        "      input_texts.append(input_text)\n",
        "      output_texts.append(output_text)\n",
        "  \n",
        "  #only train set will have input_tokenizer as none. Validation and test will will use the same.\n",
        "  if input_tokenizer is None:\n",
        "    input_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', char_level=True)\n",
        "    input_tokenizer.fit_on_texts(input_texts)\n",
        "  input_tensor = input_tokenizer.texts_to_sequences(input_texts) #generating the input tensor\n",
        "  #performing pading on the input sequences\n",
        "  input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor,padding='post')\n",
        "  \n",
        "  if output_tokenizer is None:\n",
        "    output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', char_level=True)\n",
        "    output_tokenizer.fit_on_texts(output_texts)\n",
        "  #generating the target tensor\n",
        "  output_tensor = output_tokenizer.texts_to_sequences(output_texts)\n",
        "  output_tensor = tf.keras.preprocessing.sequence.pad_sequences(output_tensor,padding='post')\n",
        "  #for dataset which is not training (validation and the testing) we pad to make maximum length same as train set.\n",
        "  if input_length is not None and output_length is not None:\n",
        "      input_tensor=tf.concat([input_tensor,tf.zeros((input_tensor.shape[0],input_length-input_tensor.shape[1]))],axis=1)\n",
        "      output_tensor=tf.concat([output_tensor,tf.zeros((output_tensor.shape[0],output_length-output_tensor.shape[1]))],axis=1)\n",
        "  #returning the input and output tokenizer, text and the tensors.\n",
        "  return input_texts,input_tensor,input_tokenizer,output_texts,output_tensor,output_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYZoLar-s1uh"
      },
      "source": [
        "# Preprocessing and reading the training data\n",
        "%%capture\n",
        "input_texts,input_tensor,input_tokenizer,target_texts,target_tensor,target_tokenizer=data(\"/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jxJdIvkttoM"
      },
      "source": [
        "# Preprocessing and reading the validation data\n",
        "%%capture\n",
        "val_input_texts,val_input_tensor,val_input_tokenizer,val_target_texts,val_target_tensor,val_target_tokenizer=data(\"/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\",input_tokenizer,target_tokenizer,input_tensor.shape[1],target_tensor.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5LiYS3jQGXn"
      },
      "source": [
        "# Preprocessing and reading the testing data\n",
        "%%capture\n",
        "test_input_texts,test_input_tensor,test_input_tokenizer,test_target_texts,test_target_tensor,test_target_tokenizer=data(\"/content/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\",input_tokenizer,target_tokenizer,input_tensor.shape[1],target_tensor.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8s1F9bzYUNd"
      },
      "source": [
        "Finding the encoder, decoder tokens and seq_lenght"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxf7x1eVjiFW"
      },
      "source": [
        "num_encoder_tokens = len(input_tokenizer.word_index)+1  #number of encoder tokens\n",
        "num_decoder_tokens = len(target_tokenizer.word_index)+1 #number of deccoder tokens\n",
        "max_encoder_seq_length =  input_tensor.shape[1]         #encoder sequence length\n",
        "max_decoder_seq_length = target_tensor.shape[1]         #deocoder sequence length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GryfWXxJyNgl"
      },
      "source": [
        "#converting the index to character\n",
        "index_to_char_input = dict((input_tokenizer.word_index[key], key) for key in input_tokenizer.word_index.keys())     #index to input character\n",
        "index_to_char_target = dict((target_tokenizer.word_index[key], key) for key in target_tokenizer.word_index.keys())  #index to output/target character"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "019RKVafn4tS"
      },
      "source": [
        "'''\n",
        "Function - Build Model\n",
        "Input - \n",
        "  The RNN cell type\n",
        "  embeding dimensions\n",
        "  no of encoder layers\n",
        "  no of decoder layers\n",
        "  dropout\n",
        "Output - It returns the model object\n",
        "'''\n",
        "#Building the model\n",
        "def build_model(rnn_type,embedding_dim,encoder_layers,decoder_layers,dropout):\n",
        "\n",
        "  '''\n",
        "  Building the Encoder\n",
        "  '''\n",
        "\n",
        "  #Specifying the dimensions of the input layer and initializing it\n",
        "  encoder_inputs = keras.Input(shape=( max_encoder_seq_length))\n",
        "  #initialization of the embeding layer\n",
        "  embed = keras.layers.Embedding(num_encoder_tokens, embedding_dim)(encoder_inputs)\n",
        "  \n",
        "  #Adding multiple layers\n",
        "  last_encoder=None #save the last encoder output for adding mutiple layers.\n",
        "\n",
        "  #######################################################################  LSTM Encoder ##################################################################### \n",
        "  if rnn_type=='LSTM':\n",
        "    #adding everything except the last LSTM layer, because in last layer return state=True\n",
        "    for i in range(encoder_layers-1):\n",
        "      encoder = keras.layers.LSTM(latent_dim, return_sequences=True,dropout=dropout) #Keras LSTM layer adding\n",
        "      if i==0:\n",
        "        encoder_out = encoder(embed)  #encoder the first layer\n",
        "      else:\n",
        "        encoder_out = encoder(last_encoder) #encode the last layer output for the next layer.\n",
        "      last_encoder=encoder_out\n",
        "    #Adding the last layer\n",
        "    encoder = keras.layers.LSTM(latent_dim, return_state=True,dropout=dropout)\n",
        "    ''' For only one encoder '''\n",
        "    if encoder_layers == 1:\n",
        "      encoder_outputs, state_h, state_c = encoder(embed)\n",
        "    else:\n",
        "      encoder_outputs, state_h, state_c = encoder(last_encoder)\n",
        "    encoder_states = [state_h, state_c] #storing both the hidden states.\n",
        "\n",
        "  #######################################################################  GRU Encoder ##################################################################### \n",
        "  elif rnn_type=='GRU':\n",
        "    #adding everything except the last GRU layer, because in last layer return state=True    \n",
        "    for i in range(encoder_layers-1):\n",
        "      encoder = keras.layers.GRU(latent_dim, return_sequences=True,dropout=dropout) #keras GRU layer\n",
        "      if i==0:\n",
        "        encoder_out = encoder(embed) #encode the first layer\n",
        "      else:\n",
        "        encoder_out = encoder(last_encoder) #encode the last layer output for the next layer\n",
        "      last_encoder=encoder_out\n",
        "    #Adding the last layer\n",
        "    encoder = keras.layers.GRU(latent_dim, return_state=True,dropout=dropout)\n",
        "    '''If there is only one encoder'''\n",
        "    if encoder_layers == 1:\n",
        "      encoder_outputs, state = encoder(embed)\n",
        "    else:\n",
        "      encoder_outputs, state = encoder(last_encoder)\n",
        "    encoder_states = [state] #Storing the encoder hidden state\n",
        "\n",
        "  #######################################################################  RNN Encoder ##################################################################### \n",
        "  elif rnn_type=='RNN':\n",
        "    #adding everything except the last RNN layer, because in last layer return state=True\n",
        "    for i in range(encoder_layers-1):      \n",
        "      encoder = keras.layers.SimpleRNN(latent_dim, return_sequences=True,dropout=dropout)\n",
        "      if i==0:\n",
        "        encoder_out = encoder(embed) #Encode the first layer\n",
        "      else:\n",
        "        encoder_out = encoder(last_encoder) #encode the last layer output for the next layer\n",
        "      last_encoder=encoder_out\n",
        "    #Adding the last layer\n",
        "    encoder = keras.layers.SimpleRNN(latent_dim, return_state=True,dropout=dropout)\n",
        "    '''If there is only one encoder'''\n",
        "    if encoder_layers == 1:\n",
        "      encoder_outputs, state = encoder(embed)\n",
        "    else:\n",
        "      encoder_outputs, state = encoder(last_encoder)\n",
        "    encoder_states = [state]  #storing the RNN encoder hidden state\n",
        "\n",
        "\n",
        "  '''\n",
        "  Building the Deocder\n",
        "  '''\n",
        "  #specifying the dimension of the input layer and initializing it\n",
        "  decoder_inputs = keras.Input(shape=( max_decoder_seq_length))\n",
        "  #initializing the embedding layer\n",
        "  embed = keras.layers.Embedding(num_decoder_tokens, embedding_dim)(decoder_inputs)\n",
        "\n",
        "  ######################################################################## LSTM Decoder #########################################################################\n",
        "  if rnn_type==\"LSTM\":\n",
        "    #adding all the LSTM layers\n",
        "    for i in range(decoder_layers):\n",
        "      decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True,dropout=dropout) #Keras LSTM layer\n",
        "      if i==0:\n",
        "        decoder_outputs, _, _ = decoder_lstm(embed, initial_state=encoder_states) #getting the decoder output for the first decoder using embed\n",
        "      else:  \n",
        "        decoder_outputs, _, _ = decoder_lstm(last, initial_state=encoder_states) #getting the decoder output for the remaining decoders\n",
        "      #geting the output from the last decoder\n",
        "      last=decoder_outputs\n",
        "\n",
        "    #Adding dense layer at the end\n",
        "    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\",name='final') #softmax dense function.\n",
        "    decoder_outputs = decoder_dense(last) #geting the final decoder outputs by calling the dense layer.\n",
        "\n",
        "  ######################################################################## GRU Decoder #########################################################################\n",
        "  elif rnn_type==\"GRU\":\n",
        "    #adding all the GRU layers\n",
        "    for i in range(decoder_layers):\n",
        "      decoder_lstm = keras.layers.GRU(latent_dim, return_sequences=True, return_state=True,dropout=dropout) #Keras GRU layer\n",
        "      if i==0:\n",
        "        decoder_outputs, _= decoder_lstm(embed, initial_state=encoder_states) #getting the decoder output for the first decoder using embed\n",
        "      else:  \n",
        "        decoder_outputs, _ = decoder_lstm(last, initial_state=encoder_states) #getting the decoder output for the remaining decoders\n",
        "      #geting the output from the last decoder\n",
        "      last=decoder_outputs\n",
        "\n",
        "    #Adding dense layer at the end\n",
        "    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\",name='final') #softmax dense function.\n",
        "    decoder_outputs = decoder_dense(last) #geting the final decoder outputs by calling the dense layer.\n",
        "\n",
        "   ######################################################################## RNN Decoder #########################################################################\n",
        "  elif rnn_type==\"RNN\":\n",
        "    #adding all the RNN layers\n",
        "    for i in range(decoder_layers):\n",
        "      decoder_lstm = keras.layers.SimpleRNN(latent_dim, return_sequences=True, return_state=True,dropout=dropout) #Keras RNN layer\n",
        "      if i==0:\n",
        "        decoder_outputs, _= decoder_lstm(embed, initial_state=encoder_states) #getting the decoder output for the first decoder using embed\n",
        "      else:  \n",
        "        decoder_outputs, _ = decoder_lstm(last, initial_state=encoder_states) #getting the decoder output for the remaining decoders\n",
        "      #geting the output from the last decoder\n",
        "      last=decoder_outputs\n",
        "\n",
        "    #Adding dense layer at the end\n",
        "    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\",name='final') #softmax dense function.\n",
        "    decoder_outputs = decoder_dense(last) #geting the final decoder outputs by calling the dense layer.\n",
        "\n",
        "  '''\n",
        "  specifying model inputs and outputs.\n",
        "    encoder_inputs  -> Input to encoder\n",
        "    decoder_inputs  -> Input to decoder for TF(Teacher forcing)\n",
        "    decoder_outputs -> Output\n",
        "  '''\n",
        "  #creating the model using the encoder inputs, decoder inputs and the decoder outputs\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  #return the keras Model Object using the defined parameters.\n",
        "  return model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaYf9aa9yKxm"
      },
      "source": [
        "'''\n",
        "Function - inferencing\n",
        "Inputs - \n",
        "  model\n",
        "  encoder_layers\n",
        "  decoder_layers\n",
        "Output - encoder model and the deocder model separately\n",
        "'''\n",
        "def inferencing(model,encoder_layers,decoder_layers):\n",
        "\n",
        "    ######################################################################### Encoder Model ###################################################################\n",
        "    # Defining the encoder_inputs\n",
        "    encoder_inputs = model.input[0]  \n",
        "    # Checking if the model layers are LSTM layers\n",
        "    if isinstance(model.layers[encoder_layers+3], keras.layers.LSTM):\n",
        "      encoder_outputs, state_h_enc, state_c_enc = model.layers[encoder_layers+3].output #geting the encoded output of the layers\n",
        "      encoder_states = [state_h_enc, state_c_enc] #getting the both hidden states of the layers\n",
        "    \n",
        "    # Checking if the model layers are GRU layers\n",
        "    elif isinstance(model.layers[encoder_layers+3], keras.layers.GRU):\n",
        "      encoder_outputs, state = model.layers[encoder_layers+3].output #geting the encoded output of the layers \n",
        "      encoder_states = [state] #getting the hidden states of the layers\n",
        "    \n",
        "    # Checking if the model layers are RNN layers\n",
        "    elif isinstance(model.layers[encoder_layers+3], keras.layers.RNN): \n",
        "      encoder_outputs, state = model.layers[encoder_layers+3].output #geting the encoded output of the layers  \n",
        "      encoder_states = [state] #getting the hidden states of the layers\n",
        "    #Genrating the encoder model\n",
        "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    ########################################################################### Decoder Model ####################################################################\n",
        "    #defining the decoder inputs\n",
        "    decoder_inputs =  keras.Input(shape=( 1))  \n",
        "    # Checking if the model layers were LSTM layers\n",
        "    if isinstance(model.layers[encoder_layers+3], keras.layers.LSTM):\n",
        "      decoder_states_inputs=[]\n",
        "      decoder_states=[]\n",
        "      last=None\n",
        "      for i in range(decoder_layers):\n",
        "        #every layer must have an input through which we can supply it's hidden state\n",
        "        decoder_state_input_h = keras.Input(shape=(latent_dim,),name='inp3_'+str(i)) #decoder state H\n",
        "        decoder_state_input_c = keras.Input(shape=(latent_dim,),name='inp4_'+str(i)) #decoder state C\n",
        "        x = [decoder_state_input_h, decoder_state_input_c] #state containing both H and C\n",
        "        decoder_lstm = model.layers[i+encoder_layers+4]\n",
        "        #If it is the first decoder layer\n",
        "        if i==0:\n",
        "          decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "              model.layers[i+encoder_layers+2](decoder_inputs), initial_state=x\n",
        "          )\n",
        "        # Consecutive decoding layers\n",
        "        else:\n",
        "          decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "              last, initial_state=x \n",
        "          )\n",
        "        #saving the final deocder outputs as last output.\n",
        "        last=decoder_outputs\n",
        "        #appending the input states and the hidden states at every layer\n",
        "        decoder_states_inputs.append (decoder_state_input_h)\n",
        "        decoder_states_inputs.append (decoder_state_input_c)\n",
        "        decoder_states.append (state_h_dec)\n",
        "        decoder_states.append (state_c_dec)\n",
        "\n",
        "    # Checking if the model layers were GRU layers\n",
        "    elif isinstance(model.layers[encoder_layers+3], keras.layers.GRU):\n",
        "      decoder_states_inputs=[] \n",
        "      decoder_states=[] \n",
        "      last=None\n",
        "      #every layer must have an input through which we can supply it's hidden state\n",
        "      for i in range(decoder_layers):\n",
        "        decoder_state_input = keras.Input(shape=(latent_dim,),name='inp3_'+str(i)) #decoder state\n",
        "        x = [decoder_state_input] #state\n",
        "        decoder_lstm = model.layers[i+encoder_layers+4]\n",
        "        #If it is the first decoder layer\n",
        "        if i==0:\n",
        "          decoder_outputs, state = decoder_lstm(\n",
        "              model.layers[i+encoder_layers+2](decoder_inputs), initial_state=x\n",
        "          )\n",
        "        # Consecutive decoding layers\n",
        "        else:\n",
        "          decoder_outputs, state = decoder_lstm(\n",
        "              last, initial_state=x \n",
        "          )\n",
        "        #saving the final deocder outputs as last output.\n",
        "        last=decoder_outputs\n",
        "        #appending the input states and the hidden states at every layer\n",
        "        decoder_states_inputs.append (decoder_state_input)\n",
        "        decoder_states.append (state)\n",
        "\n",
        "    # Checking if the model layers were RNN layers\n",
        "    elif isinstance(model.layers[encoder_layers+3], keras.layers.RNN):\n",
        "      decoder_states_inputs=[]\n",
        "      decoder_states=[]\n",
        "      last=None\n",
        "      #every layer must have an input through which we can supply it's hidden state\n",
        "      for i in range(decoder_layers):\n",
        "        decoder_state_input = keras.Input(shape=(latent_dim,),name='inp3_'+str(i)) #decoder state\n",
        "        x = [decoder_state_input] #state\n",
        "        decoder_lstm = model.layers[i+encoder_layers+4]\n",
        "        #If it is the first decoder layer\n",
        "        if i==0:\n",
        "          decoder_outputs, state = decoder_lstm(\n",
        "              model.layers[i+encoder_layers+2](decoder_inputs), initial_state=x\n",
        "          )\n",
        "        # Consecutive decoding layers\n",
        "        else:\n",
        "          decoder_outputs, state = decoder_lstm(\n",
        "              last, initial_state=x \n",
        "          )\n",
        "        #saving the final deocder outputs as last output.\n",
        "        last=decoder_outputs\n",
        "        #appending the input states and the hidden states at every layer\n",
        "        decoder_states_inputs.append (decoder_state_input)\n",
        "        decoder_states.append (state)      \n",
        "\n",
        "    '''\n",
        "    Geting ther dense final layer from the model objective\n",
        "    '''\n",
        "    decoder_dense = model.get_layer('final')\n",
        "    decoder_outputs = decoder_dense(last) #outputs of the decoder dense layer\n",
        "    #Finalizing the decoder model.\n",
        "    decoder_model = keras.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "    )\n",
        "    #returning the encoder and the decoder model for inferencing during validation of the model\n",
        "    return encoder_model,decoder_model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBRaLSUWMepJ"
      },
      "source": [
        "'''\n",
        "Function - do_predictions (Decoding the entire batch to generate the predictions)\n",
        "Input - \n",
        "  input_seq\n",
        "  encoder_model\n",
        "  decoder_model\n",
        "  batch-size\n",
        "  encoder_layers\n",
        "  decoder_layers\n",
        "Output - \n",
        "  Predicted words\n",
        "'''\n",
        "def do_predictions(input_seq,encoder_model,decoder_model,batch_size,encoder_layers,decoder_layers):\n",
        "    # use the encoder model to get the value of the states\n",
        "    states_value = encoder_model.predict(input_seq) #values of the states\n",
        "    #if GRU or RNN\n",
        "    if rnn_type=='GRU' or 'RNN':\n",
        "      states_value=[states_value]\n",
        "    #save states value for RNN, LSTM as well as GRU\n",
        "    nl=states_value\n",
        "\n",
        "    #keep on adding the states value for every deocoder layer\n",
        "    for i in range(decoder_layers-1):\n",
        "      nl=nl+states_value\n",
        "    states_value=nl\n",
        "    \n",
        "    #contains previously predicted character's index for every words in batch.\n",
        "    prev_char_index = np.zeros((batch_size, 1))\n",
        "    # starting with \\t for every word in batch hence tokenize.\n",
        "    prev_char_index[:, 0] = target_tokenizer.word_index['\\t']\n",
        "    \n",
        "    #predicted words list\n",
        "    predicted_words = [ \"\" for i in range(batch_size)]\n",
        "    #check if batch predicted or not\n",
        "    done=[False for i in range(batch_size)]\n",
        "\n",
        "    for i in range(max_decoder_seq_length):\n",
        "        out = decoder_model.predict(tuple([prev_char_index] + states_value)) #predictions of the decoder model based on the previous char index\n",
        "        output_probability=out[0] #Probability as a result of the softmax function\n",
        "        states_value = out[1:] #decoder states value is stored.\n",
        "        #for every batch we execute the following\n",
        "        for j in range(batch_size):\n",
        "          #if bacth already done\n",
        "          if done[j]:\n",
        "            continue          \n",
        "          \n",
        "          sampled_token_index = np.argmax(output_probability[j, -1, :]) #geting the sample token index\n",
        "          #if sampled index is 0 then character is nextline character\n",
        "          if sampled_token_index == 0:\n",
        "            sampled_char='\\n'\n",
        "          # otherwise convert index to the respective character\n",
        "          else:\n",
        "            sampled_char = index_to_char_target[sampled_token_index]\n",
        "          #check if it is ending\n",
        "          if sampled_char == '\\n':\n",
        "            done[j]=True\n",
        "            continue\n",
        "          #uGet the predicted words value       \n",
        "          predicted_words[j] += sampled_char\n",
        "          #update the previously predicted characters        \n",
        "          prev_char_index[j,0]=target_tokenizer.word_index[sampled_char]\n",
        "    #return the predicted words.\n",
        "    return predicted_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENyYG1Z-y6RU"
      },
      "source": [
        "'''\n",
        "Function - test_accuracy (calculate the word level accuracy (Testing accuracy))\n",
        "Input - \n",
        "  encoder_model\n",
        "  decoder_model\n",
        "  encoder_layers\n",
        "  decoder_layers\n",
        "Output - Testing accuracy \n",
        "'''\n",
        "def test_accuracy(encoder_model,decoder_model,encoder_layers,decoder_layers):\n",
        "  #count the number of words that are predicted correctly\n",
        "  success=0\n",
        "  #Get all the predicted words\n",
        "  pred=do_predictions(test_input_tensor,encoder_model,decoder_model,test_input_tensor.shape[0],encoder_layers,decoder_layers)\n",
        "\n",
        "  for seq_index in range(test_input_tensor.shape[0]):\n",
        "      predicted_word = pred[seq_index] #predicted_Word\n",
        "      target_word=test_target_texts[seq_index][1:-1] #target_word_ground_truth\n",
        "      #test the word one by one and write to files\n",
        "      #success word\n",
        "      if target_word == predicted_word:\n",
        "        success+=1\n",
        "        f = open(\"success.txt\", \"a\")\n",
        "        f.write(test_input_texts[seq_index]+' '+target_word+' '+predicted_word+'\\n')\n",
        "        f.close()\n",
        "      #failure word (if it is not correct predictions)\n",
        "      else:\n",
        "        f = open(\"failure.txt\", \"a\")\n",
        "        f.write(test_input_texts[seq_index]+' '+target_word+' '+predicted_word+'\\n')\n",
        "        f.close()\n",
        "  return float(success)/float(test_input_tensor.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX3KGZbf5Hb2"
      },
      "source": [
        "'''\n",
        "Function - batch_validate (validate entire batch)\n",
        "Input - \n",
        "  encoder_model\n",
        "  decoder_model\n",
        "  encoder_layers\n",
        "  decoder_layers\n",
        "Output - \n",
        "  Return validation accuracy\n",
        "'''\n",
        "def batch_validate(encoder_model,decoder_model,encoder_layers,decoder_layers):\n",
        "  success=0\n",
        "  #get all the predicted words\n",
        "  pred=do_predictions(val_input_tensor,encoder_model,decoder_model,val_input_tensor.shape[0],encoder_layers,decoder_layers)\n",
        "  for seq_index in range(val_input_tensor.shape[0]):\n",
        "      predicted_word = pred[seq_index] #predicted word\n",
        "      target_word=val_target_texts[seq_index][1:-1] #groundtruth word (target word)\n",
        "      #test the words one by one\n",
        "      if predicted_word == target_word:\n",
        "        success+=1 #increasing the success \n",
        "  return float(success)/float(val_input_tensor.shape[0]) #returning the accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training for Wandb Hyper parameter sweeping"
      ],
      "metadata": {
        "id": "pIwL0KL_CFD7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5zKzPicx-9x"
      },
      "source": [
        "#defining globals\n",
        "rnn_type=None\n",
        "embedding_dim=None\n",
        "model= None\n",
        "latent_dim = None\n",
        "enc_layers=None\n",
        "dec_layers=None\n",
        "'''\n",
        "Function- train()\n",
        "Performs the entire training using Wandb sweeps\n",
        "'''\n",
        "def train():\n",
        "  global rnn_type\n",
        "  global embedding_dim\n",
        "  global model\n",
        "  global latent_dim\n",
        "  global enc_layer\n",
        "  global dec_layer\n",
        "  #intializing wandb\n",
        "  wandb.init()\n",
        "  #initializing the wandb configurations\n",
        "  rnn_type=wandb.config.rnn_type              #RNN cell type\n",
        "  embedding_dim=wandb.config.embedding_dim    #embedding dimensions\n",
        "  latent_dim=wandb.config.latent_dim          #latent dimensions\n",
        "  enc_layer=wandb.config.enc_layer            #encoder_layer\n",
        "  dec_layer=wandb.config.dec_layer            #decoder layers\n",
        "  dropout=wandb.config.dropout                #dropout\n",
        "  epochs=wandb.config.epochs                  #epochs\n",
        "  bs=wandb.config.bs                          #batch size\n",
        "\n",
        "  #wandb run name initialization\n",
        "  wandb.run.name = 'epochs_'+str(epochs)+'_bs_'+str(bs)+'_rnn_type_'+str(rnn_type)+'_em_'+str(embedding_dim)+'_latd_'+str(latent_dim)+'_encs_'+str(enc_layer)+'_decs_'+str(dec_layer)+'_dr_'+str(dropout)\n",
        "\n",
        "  #building the model\n",
        "  model=build_model(rnn_type=rnn_type,embedding_dim=embedding_dim,encoder_layers=enc_layer,decoder_layers=dec_layer,dropout=dropout)\n",
        "\n",
        "  #model compilation\n",
        "  model.compile(\n",
        "      optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(\n",
        "                                                              reduction='none'), metrics=[\"accuracy\"]\n",
        "  )\n",
        "  ############################################################################### Training the model ######################################################################\n",
        "  for i in range(epochs):\n",
        "    hist=model.fit(\n",
        "        [input_tensor, target_tensor],\n",
        "        tf.concat([target_tensor[:,1:],tf.zeros((target_tensor[:,:].shape[0],1))], axis=1),\n",
        "        batch_size=bs,\n",
        "        epochs=1,shuffle=True\n",
        "    )\n",
        "    # Save model\n",
        "    model.save(\"s2s.keras\")\n",
        "    ############################################################################## Inferencing ##############################################################################\n",
        "    # Restore the model and construct the encoder and decoder.\n",
        "    inf = keras.models.load_model(\"/content/s2s.keras\")\n",
        "    encoder_model,decoder_model=inferencing(inf,encoder_layers=enc_layer,decoder_layers=dec_layer)\n",
        "    #log train loss to wandb\n",
        "    wandb.log({\"train_loss\": hist.history['loss'][0]})\n",
        "  #calculate the validation accuracy\n",
        "  val_acc=batch_validate(encoder_model,decoder_model,enc_layer,dec_layer)\n",
        "  #logging the validation accuracy\n",
        "  wandb.log({\"val_acc\":val_acc})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual Training"
      ],
      "metadata": {
        "id": "_aiDeIV3D5z7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP1dYLLlXC6y"
      },
      "source": [
        "#defining globals\n",
        "rnn_type=None\n",
        "embedding_dim=None\n",
        "model= None\n",
        "latent_dim = None\n",
        "enc_layers=None\n",
        "dec_layers=None\n",
        "'''\n",
        "Function - Manual Train\n",
        "perform the training manually for the best configuration\n",
        "'''\n",
        "def manual_train(config):\n",
        "  global rnn_type\n",
        "  global embedding_dim\n",
        "  global model\n",
        "  global latent_dim\n",
        "  global enc_layer\n",
        "  global dec_layer\n",
        "  #initializing the configured hyper-parameter values\n",
        "  rnn_type=config.rnn_type            #RNN cell type\n",
        "  embedding_dim=config.embedding_dim  #embedding dim\n",
        "  latent_dim=config.latent_dim        #latent dim\n",
        "  enc_layer=config.enc_layer          #encoder layer\n",
        "  dec_layer=config.dec_layer          #decoder layer\n",
        "  dropout=config.dropout              #dropout\n",
        "  epochs=config.epochs                #epochs\n",
        "  bs=config.bs                        #batch size\n",
        "  \n",
        "  #building the model\n",
        "  model=build_model(rnn_type=rnn_type,embedding_dim=embedding_dim,encoder_layers=enc_layer,decoder_layers=dec_layer,dropout=dropout)\n",
        "\n",
        "  #model compilation\n",
        "  model.compile(\n",
        "      optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(\n",
        "                                                              reduction='none'), metrics=[\"accuracy\"]\n",
        "  )\n",
        "  #ploting the best model\n",
        "  tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_dtype=True,show_layer_names=True, dpi=96 )\n",
        "  ##################################################################### Training #############################################################################################\n",
        "  for i in range(epochs):\n",
        "    hist=model.fit(\n",
        "        [input_tensor, target_tensor],\n",
        "        tf.concat([target_tensor[:,1:],tf.zeros((target_tensor[:,:].shape[0],1))], axis=1),\n",
        "        batch_size=bs,\n",
        "        epochs=1,shuffle=True\n",
        "    )\n",
        "    #save model\n",
        "    model.save(\"s2s.keras\")\n",
        "\n",
        "    #inferencing the model\n",
        "    inf = keras.models.load_model(\"/content/s2s.keras\")\n",
        "    encoder_model,decoder_model=inferencing(inf,encoder_layers=enc_layer,decoder_layers=dec_layer)\n",
        "    #calculating the validation accuracy\n",
        "    val_acc=batch_validate(encoder_model,decoder_model,enc_layer,dec_layer)\n",
        "    print(\"Validation Accuracy\",val_acc)\n",
        "  #calculating the testing accuracy\n",
        "  print(\"Test Accuracy\",test_accuracy(encoder_model,decoder_model,enc_layer,dec_layer))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKGZdYoS0Y0U"
      },
      "source": [
        "'''\n",
        "Wandb details importing and log in\n",
        "'''\n",
        "%%capture\n",
        "!pip install wandb\n",
        "wb=True\n",
        "import wandb\n",
        "if wb:\n",
        "  wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZOcPlID0Qkj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e042dbef55b94dab8527fab84191f026",
            "463b8e13d4944b28a7928379a6c5ac54",
            "130af60f03f749beb1c9a69525feada1",
            "134c9393f04a41c09bf47f69e3c3a34f",
            "7601668422cd455f92d0cf244e62185d",
            "ed0c7f36a1c44647b7cd7980dba00569",
            "a6af22765b04435ab64d9c98f8b3a87e",
            "a7613da9a59c4554815ba78b66b1faab",
            "74ae92db2e3c4ea79f1efab77a01af04",
            "961e99e0c26b4855b7b16c75dba1b0cd",
            "436411caab80462a859f24af15a10e30",
            "7580d9f75a1a454fa49c3350eeb68793",
            "2e1b5e1baaf240e8a97315fd00ac842d",
            "2404ca5dae104ecc820a38f172bb612c",
            "dae78f3ff7e44672971afd801e6d2310",
            "d1e8ec728c7c46a798b714536ef8e774",
            "549a793a73c04ab2bac049ce9121d863",
            "d1e7a67e3fda426cb5331e22d426badc",
            "f15c323da001441baf8d991bdb588284",
            "26ad566a7b7d4c9485109c413e001450",
            "74a90e76f8f249f5a5257b98602b75a7",
            "6c48b45f892b42e78219746e92d9ffeb",
            "3a41b6bbbf8346d8b13368192cd50fcf",
            "0f62dbab24df4815a363d2dc5218d1ce"
          ]
        },
        "outputId": "333cad1a-4913-49a1-8b62-994c3c858e0e"
      },
      "source": [
        "# generating the wandb sweep configuration\n",
        "if wb:\n",
        "  sweep_config = {\n",
        "    \"name\": \"Bayesian Sweep without attention\",\n",
        "    \"method\": \"bayes\", #method used was bayesian\n",
        "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"}, #mximizing the validation accuracy\n",
        "    \"parameters\": {\n",
        "        \n",
        "        \"rnn_type\": {\"values\": [\"GRU\",\"LSTM\"]},\n",
        "        \n",
        "        \"embedding_dim\": {\"values\": [128,256,512]},\n",
        "        \n",
        "        \"latent_dim\": {\"values\": [128,256,512,1024]},\n",
        "        \n",
        "        \"enc_layer\": {\"values\": [1, 2, 3]},\n",
        "        \n",
        "        \"dec_layer\": {\"values\": [1, 2, 3]},\n",
        "        \n",
        "        \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n",
        "\n",
        "        \"epochs\": {\"values\": [20]},\n",
        "        \n",
        "        \"bs\": {\"values\": [64]},\n",
        "\n",
        "\n",
        "    },\n",
        "  }\n",
        "  #creating the wandb sweep\n",
        "  sweep_id = wandb.sweep(sweep_config, project=\"CS6910_Assignment3_vanilla\", entity=\"cs21m007_cs21m013\")\n",
        "  #calling the wandb sweep to start the hyper parameter tuning.\n",
        "  wandb.agent(sweep_id, train, count = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: tvxoi4py\n",
            "Sweep URL: https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q1272pke with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbs: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layer: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layer: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: GRU\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220502_075402-q1272pke</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/q1272pke\" target=\"_blank\">earnest-sweep-1</a></strong> to <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py\" target=\"_blank\">https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "691/691 [==============================] - 87s 108ms/step - loss: 0.8947 - accuracy: 0.7572\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.4070 - accuracy: 0.8772\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.1584 - accuracy: 0.9498\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.1044 - accuracy: 0.9663\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0789 - accuracy: 0.9744\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0638 - accuracy: 0.9791\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0553 - accuracy: 0.9821\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0497 - accuracy: 0.9838\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0462 - accuracy: 0.9850\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0437 - accuracy: 0.9860\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0414 - accuracy: 0.9867\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0395 - accuracy: 0.9875\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0393 - accuracy: 0.9876\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0382 - accuracy: 0.9879\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0378 - accuracy: 0.9880\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0368 - accuracy: 0.9885\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0368 - accuracy: 0.9883\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0369 - accuracy: 0.9884\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0372 - accuracy: 0.9882\n",
            "691/691 [==============================] - 74s 107ms/step - loss: 0.0364 - accuracy: 0.9883\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e042dbef55b94dab8527fab84191f026"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.03644</td></tr><tr><td>val_acc</td><td>0.34052</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">earnest-sweep-1</strong>: <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/q1272pke\" target=\"_blank\">https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/q1272pke</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220502_075402-q1272pke/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rcodkkdi with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbs: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layer: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layer: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: LSTM\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220502_082216-rcodkkdi</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/rcodkkdi\" target=\"_blank\">autumn-sweep-2</a></strong> to <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py\" target=\"_blank\">https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "691/691 [==============================] - 168s 230ms/step - loss: 0.7823 - accuracy: 0.7866\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.2648 - accuracy: 0.9175\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.1400 - accuracy: 0.9553\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0950 - accuracy: 0.9695\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0690 - accuracy: 0.9777\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0535 - accuracy: 0.9825\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0438 - accuracy: 0.9860\n",
            "691/691 [==============================] - 160s 231ms/step - loss: 0.0376 - accuracy: 0.9880\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0340 - accuracy: 0.9895\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0313 - accuracy: 0.9904\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0298 - accuracy: 0.9910\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0281 - accuracy: 0.9915\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0264 - accuracy: 0.9921\n",
            "691/691 [==============================] - 159s 229ms/step - loss: 0.0258 - accuracy: 0.9924\n",
            "691/691 [==============================] - 158s 229ms/step - loss: 0.0251 - accuracy: 0.9926\n",
            "691/691 [==============================] - 158s 229ms/step - loss: 0.0240 - accuracy: 0.9930\n",
            "691/691 [==============================] - 159s 229ms/step - loss: 0.0239 - accuracy: 0.9930\n",
            "691/691 [==============================] - 159s 229ms/step - loss: 0.0236 - accuracy: 0.9930\n",
            "691/691 [==============================] - 158s 229ms/step - loss: 0.0226 - accuracy: 0.9932\n",
            "691/691 [==============================] - 159s 230ms/step - loss: 0.0219 - accuracy: 0.9936\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74ae92db2e3c4ea79f1efab77a01af04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.02189</td></tr><tr><td>val_acc</td><td>0.3832</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">autumn-sweep-2</strong>: <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/rcodkkdi\" target=\"_blank\">https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/rcodkkdi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220502_082216-rcodkkdi/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 44eqyngk with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbs: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layer: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layer: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: GRU\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220502_092742-44eqyngk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/44eqyngk\" target=\"_blank\">earthy-sweep-3</a></strong> to <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py\" target=\"_blank\">https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "691/691 [==============================] - 134s 180ms/step - loss: 0.7931 - accuracy: 0.7825\n",
            "691/691 [==============================] - 125s 180ms/step - loss: 0.2077 - accuracy: 0.9352\n",
            "691/691 [==============================] - 124s 180ms/step - loss: 0.1219 - accuracy: 0.9611\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0886 - accuracy: 0.9713\n",
            "691/691 [==============================] - 124s 180ms/step - loss: 0.0705 - accuracy: 0.9773\n",
            "691/691 [==============================] - 124s 180ms/step - loss: 0.0622 - accuracy: 0.9798\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0566 - accuracy: 0.9815\n",
            "691/691 [==============================] - 124s 180ms/step - loss: 0.0522 - accuracy: 0.9831\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0507 - accuracy: 0.9836\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0492 - accuracy: 0.9840\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0482 - accuracy: 0.9844\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0474 - accuracy: 0.9848\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0480 - accuracy: 0.9843\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0472 - accuracy: 0.9847\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0470 - accuracy: 0.9846\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0488 - accuracy: 0.9840\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0498 - accuracy: 0.9836\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0507 - accuracy: 0.9832\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0510 - accuracy: 0.9830\n",
            "691/691 [==============================] - 124s 179ms/step - loss: 0.0526 - accuracy: 0.9826\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "549a793a73c04ab2bac049ce9121d863"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.05259</td></tr><tr><td>val_acc</td><td>0.32308</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">earthy-sweep-3</strong>: <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/44eqyngk\" target=\"_blank\">https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/44eqyngk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220502_092742-44eqyngk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2asgyvfu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbs: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layer: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layer: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: GRU\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220502_101516-2asgyvfu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/runs/2asgyvfu\" target=\"_blank\">dainty-sweep-4</a></strong> to <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py\" target=\"_blank\">https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla/sweeps/tvxoi4py</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "691/691 [==============================] - 134s 181ms/step - loss: 0.8180 - accuracy: 0.7769\n",
            "691/691 [==============================] - 125s 181ms/step - loss: 0.2282 - accuracy: 0.9289\n",
            "691/691 [==============================] - 125s 182ms/step - loss: 0.1345 - accuracy: 0.9567\n",
            "691/691 [==============================] - 125s 181ms/step - loss: 0.1023 - accuracy: 0.9668\n",
            "691/691 [==============================] - 126s 182ms/step - loss: 0.0849 - accuracy: 0.9724\n",
            "691/691 [==============================] - 126s 183ms/step - loss: 0.0751 - accuracy: 0.9752\n",
            "691/691 [==============================] - 126s 183ms/step - loss: 0.0705 - accuracy: 0.9764\n",
            "691/691 [==============================] - 126s 182ms/step - loss: 0.0657 - accuracy: 0.9781\n",
            "691/691 [==============================] - 126s 182ms/step - loss: 0.0647 - accuracy: 0.9784\n",
            " 20/691 [..............................] - ETA: 2:02 - loss: 0.0591 - accuracy: 0.9803"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGmGY2dYUb13"
      },
      "source": [
        "'''\n",
        "defining the configuration for the best model.\n",
        "'''\n",
        "class best_configuration:\n",
        "  def __init__(self, rnn_type, embedding_dim,latent_dim,enc_layer,dec_layer,dropout,epochs,bs):\n",
        "    self.rnn_type = rnn_type\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.enc_layer = enc_layer\n",
        "    self.dec_layer = dec_layer\n",
        "    self.dropout = dropout\n",
        "    self.epochs = epochs\n",
        "    self.bs = bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_8Q5HtKYa8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb13af0-275f-4bc2-b6ac-41b8b1ce624a"
      },
      "source": [
        "#Trainig the best model for inferencing and generating the test accuracy\n",
        "wb=False\n",
        "if not wb:\n",
        "  config=best_configuration('LSTM',512,1024,2,3,.1,25,64)\n",
        "  manual_train(config) #calling the manual training of the function to train the best model and perform testing."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "691/691 [==============================] - 172s 237ms/step - loss: 0.8446 - accuracy: 0.7695\n",
            "Validation Accuracy 0.016291877007801745\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.2975 - accuracy: 0.9079\n",
            "Validation Accuracy 0.26984855438274435\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.1423 - accuracy: 0.9549\n",
            "Validation Accuracy 0.35429095915557596\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0920 - accuracy: 0.9708\n",
            "Validation Accuracy 0.3682882055988986\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0646 - accuracy: 0.9792\n",
            "Validation Accuracy 0.37150068838916933\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0482 - accuracy: 0.9845\n",
            "Validation Accuracy 0.3742542450665443\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0399 - accuracy: 0.9874\n",
            "Validation Accuracy 0.3838916934373566\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0344 - accuracy: 0.9895\n",
            "Validation Accuracy 0.39031665901789814\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0308 - accuracy: 0.9907\n",
            "Validation Accuracy 0.3806792106470858\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0283 - accuracy: 0.9917\n",
            "Validation Accuracy 0.3701239100504819\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0269 - accuracy: 0.9921\n",
            "Validation Accuracy 0.38756310234052316\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0258 - accuracy: 0.9925\n",
            "Validation Accuracy 0.38343276732446074\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0246 - accuracy: 0.9929\n",
            "Validation Accuracy 0.3760899495181276\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0238 - accuracy: 0.9931\n",
            "Validation Accuracy 0.37540156034878386\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0223 - accuracy: 0.9936\n",
            "Validation Accuracy 0.37976135842129416\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0218 - accuracy: 0.9936\n",
            "Validation Accuracy 0.3939880679210647\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0212 - accuracy: 0.9938\n",
            "Validation Accuracy 0.3820559889857733\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0210 - accuracy: 0.9939\n",
            "Validation Accuracy 0.3781551170261588\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0207 - accuracy: 0.9939\n",
            "Validation Accuracy 0.38458008260670035\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0196 - accuracy: 0.9942\n",
            "Validation Accuracy 0.3935291418081689\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0194 - accuracy: 0.9942\n",
            "Validation Accuracy 0.3900871959614502\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0187 - accuracy: 0.9944\n",
            "Validation Accuracy 0.3919229004130335\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0183 - accuracy: 0.9945\n",
            "Validation Accuracy 0.39743001376778336\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0181 - accuracy: 0.9945\n",
            "Validation Accuracy 0.4017898118402937\n",
            "691/691 [==============================] - 164s 237ms/step - loss: 0.0176 - accuracy: 0.9946\n",
            "Validation Accuracy 0.39031665901789814\n",
            "Test Accuracy 0.38605064415815193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FDqD1KI2J1Dq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}