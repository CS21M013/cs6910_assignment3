# CS6910 Fundamentals of Deep Learning (Assignment 3)
## Use recurrent neural networks to build a transliteration system.
The wandb report can be accessed from here - https://wandb.ai/cs21m007_cs21m013/CS6910_Assignment3_vanilla_final_2/reports/CS6910-Assignment-3-Seq2seq-Character-level-Neural-Machine-Transliteration--VmlldzoxOTYzNTUy

This Repository contains 3 sub folders  
1. The Vanilla seq2seq folder contains everything required to explain the Vanilla model and all the outputs of the Vanilla model as well.
2. The attention seq2seq folder contains everything needed to explain the attention model and the outputs generated as a result of running the best attention based model.
3. The GPT, transformer based model.
